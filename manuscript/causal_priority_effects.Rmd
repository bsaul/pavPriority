---
title: Causal Priority Effects
authors:
- name: Bradley Saul
- name: Fletcher Halliday
output: 
  pdf_document
header-includes: 
- \usepackage{mathtools}
- \usepackage{tikz}
- \usepackage{graphicx}
- \usepackage{xcolor}
- \newcommand*\circled[1]{\tikz[baseline=(char.base)]{
     \node[shape=circle,draw,inner sep=2pt] (char) {#1};}}
bibliography: "priority_effects.bib"
abstract: TBD
---


# Introduction

The early bird gets the worm, but the second mouse gets the cheese. Despite being poorly understood and studied, priority effects -- the order and timing of species arrival -- have ecological consequences [@fukami2015historical]. Priority effects invite counterfactual reasoning: if species A arrives first would outcomes for species B be different compared to a world where species B arrived first? Such counterfactual questions are well suited for the potential framework of causal inference [@vanderweele2015explanation]. 

To study within-host priority effects, @halliday2017interactions conducted an experiment wherein three cohorts of sentinel, pathogen-na{\:i}ve tall fescue (*Festuca arundinacea*) plants where placed in a field at three different timepoints during the year. The timepoints were chosen to correspond to periods of high prevelance during the annual epidemic cycles for each of three tall fescue fungal pathogens: *Colletotrichum* (early summer), *Rhizoctonia* (mid summer), and *Puccinia* (late summer) [@halliday2017interactions]. 

A goal of this paper is to introduce experimental ecologist to the causal inference methods of XXX, YYY, ZZZ. To do so, we begin by expressing priority effects as functions of potential outcomes, thus giving contrasts of potential outcomes a causal interpretation. We discuss the assumptions necessary for identifying and estimating such effects from observed data. Causal inference methods more familiar to many ecologists such as structural equation models make certain implicit assumptions, which, if violated, may lead to incorrect conclusions [@imai2010general]. After establishing the targets of inference (estimands) and assumptions necessary for causal inference, statistical models are parameterized to target the estimands and estimatation and inference carried out.

## Priority Effects

Describe priority effects and importance to ecology (based on @fukami2015historical)

* Is hypothesis in this experiment niche preemption or niche modification? I think modification, though this complicated if a species can change from (e.g.) biotroph to necrotroph.
* link priority effects to causal mediation:
   * mediation - how an effect occurs; interaction - for whom an effect occurs [@vanderweele2015explanation]
   * would be nice to map one of the figures in @fukami2015historical to the causal mediation SWIT
   
Wrinkle with this study/data

* randomized exposure (time of field placement) is essentially an instrumental variable
* interval censored data
* is death of leaf a censoring event or competing risk? There's a complication that leaves only live a certain period of time - during which they are either infected or not - but it is not as if a leaf *could* survive for longer during which time we could observe the outcome. Then there's the fact that leaves in the last cohort can't be observed for the same length of time as other cohorts due to end of study and senesence. 

## Causal inference using potential outcomes

Structural equation models [@shipley2016cause] are popular in biology and ecology; however, parameters from these models may not carry a causal interpretation without assumptions often implicitly made [@imai2010general]. 

* the approach we describe starts from causal questions and works towards statistical “answers” (i.e. parameter estimates, confidence intervals, hypothesis tests, etc)
* the typical approach, however, is to take statistical “answers” and assume they are causal
* a more principled approach is warranted and available
* @imai2010general argue the structural equation modeling approach to mediation “is problematic for 3 reasons: the lack of a general definition of causal mediation effects independent of a particular statistical model, the inability to specify the key identification assumption, and the difficulty of extending the framework to nonlinear models.”


Problems with linear structural equation models [@imai2010general]:

* within LSEM, causal mediation effects are defined relative to particular statistical models
* not generalization to nonlinear models [is this true for the SEM framework?]

An advantage of the potential outcome approach is that the causal effects can be defined, identified, and estimators derived without reference to specific statistical models [@imai2010general].

## Organization

The paper is organized as follows:

* causal model for priority effects
    * experimental description
    * notation
    * graphic model
    * defining causal estimands and clarifying the link between these and priority effects
    * identifiability 
    * limitations and “gotchas” of this section
* statistical model
    * why this model?
    * estimator
    * limitation and “gotchas” with this model/estimator
* results
    * numerical results and interpretation
    * stability and sensitivity checks
* discussion
    * what do these results mean?
    * a call for more causal in causal
    * suggestions for better designs and how identifiability results might suggest better design
    * links to other causal frameworks (such as sufficient causes)
  


# A Causal Model for Priority Effects

* First describe the target causal estimand; introduce notation
* Then describe an idealized randomized experiment from which the estimand could be straightfowardly estimated
* Then describe issues with this experiment (why it is difficult to carry out)
* Then describe the experiment that was conducted in @halliday2017interactions

## Experiment

Describe the experiment that was run:

* experimental treatments
* what was measured

Describe study predictions or hypotheses.

## Notation

* Define units
* Define variables

Let $A = \{0, 1\}$ be exposure to either low prevelance (0) or high prevelance (1) of *Collectotricum*. Let $M(a)$ be the binary indicator of visible *Collectotricum* symptoms under exposure setting $a$ during the first four weeks after leaf emergence. Let $Y(a, m)$ be the binary indicator of visible *Rhizoctonia* symptoms four weeks after leaf emergence.


* Is $M(a)$ time to infection or just an indicator of infection? Latter is probably easier to deal with.
* Is $M(a)$ infection by either collectotricum or rhizoctonium (or nothing) (i.e. a competing risks problem) or just infection by, say, just collectotricum or not?

Assumes no-interference. Plausible here? Are units far enough away in space such that treatment of one unit does not effect outcome in another unit?

## Graphical Model

The more algebraic potential outcomes (sometimes referred to as the counterfactual or Rubin causal model [holland1986]) and directed acyclic graphs (DAGs) have sometimes been viewed as different approaches for understanding causality. We see both approaches as useful and we use single world intervention graphs (SWIGs) or single world intervention templates (SWITs) [@richardson2013primer] to explicitly represent potential outcomes on a graph


```{r tikz-ex, engine = "tikz", fig.cap = "Scenario I: SWIGs for the three potential worlds considered in this experiment", fig.ext = 'pdf', echo = FALSE}
\usetikzlibrary{arrows, shapes, calc, shapes.geometric, fit}

\tikzset{
container/.style = {
    rectangle,
    draw,
    inner sep=10 mm,
    dashed,
    node contents={}}
}

\begin{tikzpicture}[node distance=2cm, auto, thick, scale = 0.5]
\begin{scope}
\node (A) [draw, semicircle, rotate = 90] {\rotatebox{270}{$A$} };
\node (a) [draw, red, semicircle, rotate = 270] at ($(A)+(40pt,0)$) {\rotatebox{90}{$a$} };
\node (L1) [right of = a, draw, circle]  {$L_1(\textcolor{red}{a})$};
\node (M1) [above of = L1, draw, semicircle, rotate = 90] {\rotatebox{270}{$M_1(\textcolor{red}{a})$}};
\node (m1) [draw, red, semicircle, rotate = 270] at ($(M1)+(65pt,0)$) {\rotatebox{90}{$m_1$} };
\node (Y1) [right of = m1, draw, circle]  {$Y_1(\textcolor{red}{a}, \textcolor{red}{m_1})$};
\node (L2) [above of = Y1, draw, circle]  {$L_2(\textcolor{red}{a})$};
\node (M2) [above of = L2, draw, semicircle, rotate = 90] {\rotatebox{270}{$M_2(\textcolor{red}{a})$}};
\node (m2) [draw, red, semicircle, rotate = 270] at ($(M2)+(65pt,0)$) {\rotatebox{90}{$m_2$} };
\node (Y2) [right of = m2, draw, circle] {$Y_2(\textcolor{red}{a}, \textcolor{red}{m_2})$};
\end{scope}

\node [container,
       fit=(A) (Y2)];
\node [container,
       fit=(L1) (Y1)];
\node [container,
       fit=(L2) (Y2)];

\draw[->, rounded corners = 15pt] (a) -- (2,3) -- (4,5)  -- (Y1);
\path[->, blue, bend right] (a) edge (Y1);
\path[->, blue] (a) edge (M1);
\path[->, blue] (a) edge (L1);
\path[->, blue, bend right] (a) edge (Y2);
\path[->, blue] (a) edge (M2);

\path[->, red] (a) -- (0,1) -- (L2); 
\draw[->, blue, rounded corners = 15pt] (a) --  (5,8) -- (L2);

\path[->] (a) edge [out=0, in=-90] (Y1);

\path[->, blue] (m1) edge (Y1);
\path[->, blue] (L1) edge (M1);
\path[->, blue] (L1) edge (Y1);

\path[->, blue] (m2) edge (Y2);
\path[->, blue] (L2) edge (M2);
\path[->, blue] (L2) edge (Y2);

\end{tikzpicture}
```

## Possible Estimands - targets of inference

First we layout a generic framework defining causal effects before specifying priority causal effects. 

A causal effect is in general a contrast between a functional, denoted $\mathcal{F}$, of the distribution of potential outcomes under different settings. 

\[
CE[Y(a, m), Y(a’, m’); \mathcal{F}]
\]

Often $\mathcal{F} \coloneqq \mathrm{E}(\cdot)$, i.e., an expectation, but other features of the distribution such as quantiles or survival curves may be of interest too. The contrast function may be the difference, ratio, odds ratio, or whatever. 

Here, we follow @imai2010general in defining causal mediation effects.

Average direct effect of treatment:

\[
DE(a, a’, a^{\star}) = \mathrm{E}[Y(a, M(a^{\star})) - Y(a’, M(a^{\star}))]
\]

This the effect of setting treatment from $a$ to $a’$ while the mediator takes the value it would take under $a^{\star}$, allowing for $a^{\star} = a$ or $a’$.

Average causal mediation effect (the effect of the treatment through the mediator):

\[
ME(a, a’, a^{\star}) = \mathrm{E}[Y(a, M(a’)) - Y(a, M(a^{\star}))]
\]

For example, $ME(0, 1, 1) = \mathrm{E}[Y(0, M(1)) - Y(0, M(0))]$ asks the question: what would be the effect on the outcome of changing the mediator from its value under control to its value under SA while holding the treatment at the control value? 

A table or figure describing the link between hypotheses and causal effects:

* Fletcher: lay out hypotheses about effects of SA and JA and how you expect these effects to be mediated.

## Identifiability Assumptions

\[
Y(a, m), M(a) \perp A | L = l
\]


\[
Y(a, m) \perp M(a) | A, L = l
\]

First holds trivially due to randomization.

Second is strong assumption. $L$ are *pretreatment* variables. Further assumptions are needed for time-varying confounding.


	

# Mapping to a statistical model

* note that we don’t make no-interaction assumption.

# Discussion

Worth discussing @suzuki2011identification and the sufficient cause model?

# References